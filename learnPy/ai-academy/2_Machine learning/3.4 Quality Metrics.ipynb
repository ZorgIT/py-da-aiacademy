{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Метрики качества — это специальные показатели для оценки результата модели.\n",
    "\n",
    "True Positive (TP) — случай, когда объект действительно относился к типу, который предсказал алгоритм. Если алгоритм говорит, что человек болен, и он правда болеет (нижний правый угол).\n",
    "\n",
    "False Positive (FP) — случай, когда алгоритм предсказал, что человек болен, хотя на самом деле пациент здоров (нижний левый угол).\n",
    "\n",
    "False Negative (FN) — случай, когда алгоритм предсказал, что человек здоров, хотя на самом деле он болен (верхний правый угол).\n",
    "\n",
    "И наконец, True Negative (TN) — случай, когда здоровому пациенту алгоритм сказал, что он здоров (верхний левый угол).\n",
    "Матрица ошибок помогает оценить и выбрать метрики качества в задачах классификации. Ведь качество классификатора определяется именно ошибками, которые он допускает."
   ],
   "id": "ef43569e43376bbf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Аccuracy** — доля правильных ответов. Это самая простая и понятная метрика качества классификации.\n",
    "\n",
    "Формула метрики очень проста: делим верно определенные объекты на количество всех объектов.\n",
    "\n",
    "Данная метрика не всегда правильно отражает качество модели, особенно когда есть дисбаланс классов, например, в исходных данных у нас может быть очень много фото котиков и очень мало фото песиков.\n",
    "\n",
    "\n",
    "**Recall (полнота)** — отношение всех правильно угаданных объектов предсказываемого класса к общему количеству истинных объектов этого класса.\n",
    "Идеально, если метрика Recall будет иметь высокое значение.\n",
    "\n",
    "Метрика Recall поможет узнать, сколько объектов нужного класса нашёл классификатор. \n",
    "\n",
    "Recall показывает, действительный класс объекта 1 (например, «котики»), в том случае, если классификатор его правильно предсказал. Формула метрики:\n",
    "\n",
    "Recall = TP/(TP + FN) = 3/(3+1) = 0.75\n",
    "\n",
    "**Precision (точность)** — отношение правильно определенных объектов искомого класса к общему количеству предсказанных объектов этого класса.\n",
    "метрика расскажет, как часто классификатор прав, когда предсказывает класс 1 («котики»).\n",
    "Precision = TP/(TP + FP) = 3/(3 + 2) = 0.6\n",
    "\n",
    "**F-мера** — среднее значение точности и полноты, у хорошего алгоритма показывает высокое значение близкое к 1. \n",
    "\n",
    "F-score = (2 * Recall * Precision)/(Recall + Precision) = (2*0.75*0.6)/(0.75 + 0.6) = 0.67\n",
    "\n",
    "F-мера стремится к нулю, если точность или полнота стремится к нулю. Эта формула придает одинаковый вес точности и полноте, поэтому значение метрики будет падать одинаково при уменьшении и точности, и полноты — это **сбалансированная F-мера**\n",
    "\n",
    "### промежуточный итог\n",
    "\n",
    "Мы посчитали все метрики для примера с котиками и песиками:\n",
    "\n",
    "- Accuracy = 70% означает, что классификатор ошибается в 3 котах из 10, а 7 определяет правильно.\n",
    "- Precision = 60% означает, что метка «кот» 4 раза из каждых 10 котов неверна (на самом деле это собаки, модель ошибается), а остальные 6 котов определены верно.\n",
    "- Recall = 70% означает, что 3 из каждых истинных 10 котов были пропущены моделью, а другие 7 правильно определены как «кот».\n",
    "\n",
    "\n"
   ],
   "id": "f99e51a16e41793"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Метрика ROC-AUC\n",
    "\n",
    "\n",
    "Precision и Recall также используют вместе для построения кривой PR-AUC и аналогично AUC-ROC находят площадь под ней. Иногда она даже более показательна, чем ROC-AUC. Особенно советуем использовать её для больших датасетов. На графике точность и полнота являются осями плоскости:"
   ],
   "id": "4a518a7942ab524f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50f7bcf4a0cafa78"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
